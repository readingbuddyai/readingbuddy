#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸°ë³¸ ëª¨ë¸, LoRA r16, LoRA r32 ì„±ëŠ¥ ë¹„êµ
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime

# ë¹„êµí•  ëª¨ë¸ë“¤ ì •ì˜ (ì´ 7ê°œ)
MODELS = {
    "base": {
        "name": "ê¸°ë³¸ ëª¨ë¸ (wav2vec2-korean-phoneme)",
        "path": "/home/j-k13a206/models/wav2vec2-korean-phoneme",
        "output": "results_base.json"
    },
    # LoRA r16 ëª¨ë¸ë“¤ (checkpoints_full)
    "lora_r16_3500h": {
        "name": "LoRA r16 (3500h)",
        "path": "/home/j-k13a206/fine_tunining_new/checkpoints_full/phase1_full_3500h/final_model",
        "output": "results_lora_r16_3500h.json"
    },
    "lora_r16_early3": {
        "name": "LoRA r16 (3500h, Early Stop 3)",
        "path": "/home/j-k13a206/fine_tunining_new/checkpoints_full/phase1_full_3500h_earlystop3/final_model",
        "output": "results_lora_r16_early3.json"
    },
    "lora_r16_early15": {
        "name": "LoRA r16 (3500h, Early Stop 15)",
        "path": "/home/j-k13a206/fine_tunining_new/checkpoints_full/phase1_full_3500h_earlystop15/final_model",
        "output": "results_lora_r16_early15.json"
    },
    # LoRA r32 ëª¨ë¸ë“¤ (checkpoints_full_r32)
    "lora_r32_3500h": {
        "name": "LoRA r32 (3500h)",
        "path": "/home/j-k13a206/fine_tunining_new/checkpoints_full_r32/phase1_full_3500h_r32/final_model",
        "output": "results_lora_r32_3500h.json"
    },
    "lora_r32_early3": {
        "name": "LoRA r32 (3500h, Early Stop 3)",
        "path": "/home/j-k13a206/fine_tunining_new/checkpoints_full_r32/phase1_full_3500h_r32_ealry3/final_model",
        "output": "results_lora_r32_early3.json"
    },
    "lora_r32_early15": {
        "name": "LoRA r32 (3500h, Early Stop 15)",
        "path": "/home/j-k13a206/fine_tunining_new/checkpoints_full_r32/phase1_full_3500h_r32_ealry15/final_model",
        "output": "results_lora_r32_early15.json"
    }
}

def run_evaluation(model_id, model_info, gpu="3", test_dir=None):
    """ë‹¨ì¼ ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""

    if test_dir is None:
        test_dir = "/home/j-k13a206/data/child_subset_100h/3.Test"

    model_path = model_info["path"]
    output_path = Path("/home/j-k13a206/fine_tunining_new/comparison_results") / model_info["output"]

    print("\n" + "=" * 80)
    print(f"ğŸš€ í‰ê°€ ì‹œì‘: {model_info['name']}")
    print(f"ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    print("=" * 80)

    # ê²½ë¡œ ì¡´ì¬ í™•ì¸
    if not Path(model_path).exists():
        print(f"âŒ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None

    # evaluate_test.py ì‹¤í–‰
    cmd = [
        "python3",
        "/home/j-k13a206/fine_tunining_new/evaluate_test.py",
        "--model", model_path,
        "--test_dir", test_dir,
        "--gpu", gpu,
        "--output", str(output_path)
    ]

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8'
        )

        # ì¶œë ¥ í‘œì‹œ
        print(result.stdout)
        if result.stderr:
            print("STDERR:", result.stderr)

        if result.returncode != 0:
            print(f"âŒ í‰ê°€ ì‹¤íŒ¨ (exit code: {result.returncode})")
            return None

        # ê²°ê³¼ ë¡œë“œ
        if output_path.exists():
            with open(output_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            print(f"âœ… í‰ê°€ ì™„ë£Œ: PER {results['per']*100:.2f}%")
            return results
        else:
            print(f"âŒ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def compare_results(all_results):
    """ëª¨ë“  ê²°ê³¼ ë¹„êµ ë° ìš”ì•½"""

    print("\n\n" + "=" * 80)
    print("ğŸ“Š ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ (ì´ 7ê°œ)")
    print("=" * 80)

    # í…Œì´ë¸” í—¤ë”
    print(f"\n{'ëª¨ë¸ëª…':<45} {'PER':>10} {'CER':>10} {'ê°œì„ ìœ¨':>10} {'ì„±ê³µ':>10}")
    print("-" * 90)

    # ê¸°ë³¸ ëª¨ë¸ PER
    base_per = all_results.get("base", {}).get("per", 1.0) if all_results.get("base") else 1.0

    # ê²°ê³¼ ì •ë ¬ (PER ê¸°ì¤€)
    sorted_results = sorted(
        all_results.items(),
        key=lambda x: x[1]['per'] if x[1] else float('inf')
    )

    best_model = None
    best_per = float('inf')

    for model_id, results in sorted_results:
        model_name = MODELS[model_id]['name']

        if results is None:
            print(f"{model_name:<45} {'N/A':>10} {'N/A':>10} {'N/A':>10} {'N/A':>10}")
            continue

        per = results['per'] * 100
        cer = results['cer'] * 100
        success = results['success_count']

        # ê°œì„ ìœ¨ ê³„ì‚°
        if model_id == "base":
            improvement = "-"
        else:
            improvement_rate = ((base_per - results['per']) / base_per) * 100
            improvement = f"{improvement_rate:+.1f}%"

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì¶”ì 
        if per < best_per:
            best_per = per
            best_model = model_name

        # ê²°ê³¼ ì¶œë ¥
        marker = " ğŸ†" if model_id == sorted_results[0][0] and results else ""
        print(f"{model_name:<45} {per:>9.2f}% {cer:>9.2f}% {improvement:>10} {success:>10,}{marker}")

    print("-" * 90)

    # ìƒì„¸ ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ìƒì„¸ ë¶„ì„")
    print("=" * 80)

    if "base" in all_results and all_results["base"]:
        base_per_val = all_results["base"]["per"] * 100
        print(f"\nğŸ”¹ ê¸°ë³¸ ëª¨ë¸ PER: {base_per_val:.2f}%")

    # LoRA r16 ê·¸ë£¹ ë¶„ì„
    print("\nğŸ“¦ LoRA r16 ëª¨ë¸ë“¤:")
    r16_models = ["lora_r16_3500h", "lora_r16_early3", "lora_r16_early15"]
    r16_best = None
    r16_best_per = float('inf')

    for model_id in r16_models:
        if model_id in all_results and all_results[model_id]:
            per = all_results[model_id]["per"] * 100
            improvement = ((base_per - all_results[model_id]["per"]) / base_per) * 100
            print(f"  â€¢ {MODELS[model_id]['name']}: {per:.2f}% (ê°œì„ : {improvement:+.1f}%)")
            if per < r16_best_per:
                r16_best_per = per
                r16_best = model_id

    # LoRA r32 ê·¸ë£¹ ë¶„ì„
    print("\nğŸ“¦ LoRA r32 ëª¨ë¸ë“¤:")
    r32_models = ["lora_r32_3500h", "lora_r32_early3", "lora_r32_early15"]
    r32_best = None
    r32_best_per = float('inf')

    for model_id in r32_models:
        if model_id in all_results and all_results[model_id]:
            per = all_results[model_id]["per"] * 100
            improvement = ((base_per - all_results[model_id]["per"]) / base_per) * 100
            print(f"  â€¢ {MODELS[model_id]['name']}: {per:.2f}% (ê°œì„ : {improvement:+.1f}%)")
            if per < r32_best_per:
                r32_best_per = per
                r32_best = model_id

    # r16 vs r32 ìµœê³  ëª¨ë¸ ë¹„êµ
    if r16_best and r32_best:
        diff = r16_best_per - r32_best_per
        print(f"\nğŸ”¸ ìµœê³  r16 vs ìµœê³  r32 ë¹„êµ:")
        print(f"  â€¢ ìµœê³  r16: {MODELS[r16_best]['name']} - {r16_best_per:.2f}%")
        print(f"  â€¢ ìµœê³  r32: {MODELS[r32_best]['name']} - {r32_best_per:.2f}%")
        print(f"  â€¢ ì°¨ì´: {diff:+.2f}%p")
        if diff > 0:
            print(f"  âœ… r32ê°€ r16ë³´ë‹¤ {abs(diff):.2f}%p ë” ìš°ìˆ˜")
        elif diff < 0:
            print(f"  âœ… r16ì´ r32ë³´ë‹¤ {abs(diff):.2f}%p ë” ìš°ìˆ˜")
        else:
            print(f"  âš–ï¸  r16ê³¼ r32 ì„±ëŠ¥ì´ ë™ì¼")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    if best_model:
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
        print(f"   PER: {best_per:.2f}%")

        if best_per < 15:
            print(f"   âœ… ëª©í‘œ ë‹¬ì„±! (PER < 15%)")
        elif best_per < 18:
            print(f"   âš ï¸ ëª©í‘œì— ê·¼ì ‘ (PER < 18%)")
        else:
            print(f"   âŒ ëª©í‘œ ë¯¸ë‹¬ì„± (PER > 18%)")

    print("\n" + "=" * 80)

    # ì¢…í•© ë¹„êµ JSON ì €ì¥
    comparison_path = Path("/home/j-k13a206/fine_tunining_new/comparison_results/summary.json")
    comparison_data = {
        "timestamp": datetime.now().isoformat(),
        "best_model": best_model,
        "best_per": best_per,
        "results": {
            model_id: {
                "name": MODELS[model_id]['name'],
                "per": results['per'] * 100 if results else None,
                "cer": results['cer'] * 100 if results else None,
                "success_count": results['success_count'] if results else None,
            }
            for model_id, results in all_results.items()
        }
    }

    comparison_path.parent.mkdir(parents=True, exist_ok=True)
    with open(comparison_path, 'w', encoding='utf-8') as f:
        json.dump(comparison_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ë¹„êµ ê²°ê³¼ ì €ì¥: {comparison_path}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description='ê¸°ë³¸ ëª¨ë¸ vs LoRA r16 vs LoRA r32 ë¹„êµ')
    parser.add_argument('--gpu', type=str, default='3', help='GPU ë²ˆí˜¸')
    parser.add_argument('--test_dir', type=str,
                        default='/home/j-k13a206/data/child_subset_100h/3.Test',
                        help='Test ë””ë ‰í† ë¦¬ ê²½ë¡œ')

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸ¯ ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ê¸°ë³¸ + r16Ã—3 + r32Ã—3)")
    print("=" * 80)
    print(f"ğŸ“¦ ë¹„êµí•  ëª¨ë¸ ìˆ˜: {len(MODELS)}ê°œ")
    print(f"   â€¢ ê¸°ë³¸ ëª¨ë¸: 1ê°œ")
    print(f"   â€¢ LoRA r16 ëª¨ë¸: 3ê°œ")
    print(f"   â€¢ LoRA r32 ëª¨ë¸: 3ê°œ")
    print(f"ğŸ–¥ï¸  GPU: {args.gpu}")
    print(f"ğŸ“‚ Test ë””ë ‰í† ë¦¬: {args.test_dir}")
    print("=" * 80)

    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    results_dir = Path("/home/j-k13a206/fine_tunining_new/comparison_results")
    results_dir.mkdir(parents=True, exist_ok=True)

    # ëª¨ë“  ëª¨ë¸ í‰ê°€
    all_results = {}

    for i, (model_id, model_info) in enumerate(MODELS.items(), 1):
        print(f"\n{'='*80}")
        print(f"ì§„í–‰: {i}/{len(MODELS)}")
        print(f"{'='*80}")

        results = run_evaluation(
            model_id=model_id,
            model_info=model_info,
            gpu=args.gpu,
            test_dir=args.test_dir
        )

        all_results[model_id] = results

    # ê²°ê³¼ ë¹„êµ
    compare_results(all_results)

    print("\nâœ… ëª¨ë“  ë¹„êµ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
