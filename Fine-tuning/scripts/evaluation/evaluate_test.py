#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test ì…‹ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ í‰ê°€
WER (Word Error Rate) ê³„ì‚°
"""

import os
import sys
import json
import argparse
import glob
import numpy as np
import torch
import soundfile as sf
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
from jiwer import wer, cer
from peft import PeftModel

sys.path.append('/home/j-k13a206/finetunning/organized/03_data_processing')
from korean_g2p import KoreanG2P


def load_model_and_processor(model_path: str, device: str):
    """ëª¨ë¸ê³¼ Processor ë¡œë“œ (LoRA ì§€ì›)"""
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    model_path = str(Path(model_path).resolve())

    print(f"\nğŸ“¦ Processor ë¡œë“œ")
    processor = Wav2Vec2Processor.from_pretrained(
        '/home/j-k13a206/models/wav2vec2-korean-phoneme'
    )

    print(f"\nğŸ¤– ëª¨ë¸ ë¡œë“œ: {model_path}")

    # adapter_config.jsonì´ ìˆëŠ”ì§€ í™•ì¸ (LoRA ëª¨ë¸ì¸ì§€)
    adapter_config_path = Path(model_path) / "adapter_config.json"

    if adapter_config_path.exists():
        # LoRA ëª¨ë¸ ë¡œë“œ
        print("  LoRA ëª¨ë¸ ê°ì§€ - PEFTë¡œ ë¡œë“œ")
        # ë² ì´ìŠ¤ ëª¨ë¸ ë¨¼ì € ë¡œë“œ
        base_model = Wav2Vec2ForCTC.from_pretrained(
            '/home/j-k13a206/models/wav2vec2-korean-phoneme'
        )
        # LoRA ì–´ëŒ‘í„° ë¡œë“œ
        model = PeftModel.from_pretrained(base_model, model_path)
        # ì¶”ë¡ ì„ ìœ„í•´ merge (ì„ íƒì‚¬í•­, ì†ë„ í–¥ìƒ)
        model = model.merge_and_unload()
    else:
        # ì¼ë°˜ ëª¨ë¸ ë¡œë“œ
        print("  ì¼ë°˜ ëª¨ë¸ë¡œ ë¡œë“œ")
        model = Wav2Vec2ForCTC.from_pretrained(model_path)

    model.to(device)
    model.eval()

    return model, processor


def phonemes_to_text(phonemes: str) -> str:
    """ìŒì†Œë¥¼ ëŒ€ëµì ì¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ì—­ë³€í™˜)"""
    # ì‹¤ì œë¡œëŠ” g2pì˜ ì—­ë³€í™˜ì´ í•„ìš”í•˜ì§€ë§Œ, í‰ê°€ë¥¼ ìœ„í•´ ìŒì†Œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    return phonemes


def evaluate_test_set(
    model,
    processor,
    g2p: KoreanG2P,
    test_dir: str,
    device: str,
    max_samples: int = None
):
    """Test ì…‹ í‰ê°€"""

    # Test JSON íŒŒì¼ ìˆ˜ì§‘
    test_path = Path(test_dir)
    json_pattern = str(test_path / "**/*.json")
    json_files = sorted(glob.glob(json_pattern, recursive=True))

    if max_samples:
        json_files = json_files[:max_samples]

    print(f"\nğŸ“Š Test ì…‹: {len(json_files):,}ê°œ ìƒ˜í”Œ")

    references = []  # ì •ë‹µ ìŒì†Œ
    hypotheses = []  # ì˜ˆì¸¡ ìŒì†Œ

    success_count = 0
    error_count = 0

    print("\nğŸ” í‰ê°€ ì¤‘...")
    for json_path in tqdm(json_files, desc="Evaluating"):
        try:
            # JSON ë¡œë“œ
            with open(json_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            # WAV ê²½ë¡œ êµ¬ì„±
            filename = metadata['File']['FileName']
            json_path_obj = Path(json_path)
            parts = json_path_obj.parts

            # ë¼ë²¨ë§ë°ì´í„° â†’ ì›ì²œë°ì´í„°
            try:
                labeling_idx = parts.index("ë¼ë²¨ë§ë°ì´í„°")
                relative_parts = parts[labeling_idx + 1:]
            except ValueError:
                error_count += 1
                continue

            wav_path = test_path / "ì›ì²œë°ì´í„°" / Path(*relative_parts[:-1]) / filename

            if not wav_path.exists():
                error_count += 1
                continue

            # ì˜¤ë””ì˜¤ ë¡œë“œ
            speech, sr = sf.read(str(wav_path))

            if len(speech) < 1600:  # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
                error_count += 1
                continue

            # ì •ë‹µ í…ìŠ¤íŠ¸
            text = metadata['Transcription']['LabelText'].strip()
            if not text:
                error_count += 1
                continue

            # ì •ë‹µ ìŒì†Œ
            ref_phonemes = g2p.text_to_phonemes(text)
            if not ref_phonemes:
                error_count += 1
                continue

            # ìŒì„± ì¸ì‹ (ì˜ˆì¸¡)
            input_values = processor(
                speech,
                sampling_rate=16000,
                return_tensors="pt",
                padding=False
            ).input_values.to(device)

            with torch.no_grad():
                logits = model(input_values).logits

            # ë””ì½”ë”©
            predicted_ids = torch.argmax(logits, dim=-1)
            pred_phonemes = processor.batch_decode(predicted_ids)[0]

            # ì €ì¥
            references.append(ref_phonemes)
            hypotheses.append(pred_phonemes)
            success_count += 1

        except Exception as e:
            error_count += 1
            continue

    print(f"\nâœ… ì„±ê³µ: {success_count:,}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {error_count:,}ê°œ")

    if not references or not hypotheses:
        print("\nâš ï¸ í‰ê°€í•  ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤!")
        return None

    # WER/CER ê³„ì‚°
    print("\n" + "=" * 80)
    print("ğŸ“ˆ í‰ê°€ ê²°ê³¼")
    print("=" * 80)

    # ìŒì†Œ ë‹¨ìœ„ WER (Phoneme Error Rate, PER)
    per_score = wer(references, hypotheses)
    print(f"\nğŸ¯ PER (Phoneme Error Rate): {per_score*100:.2f}%")

    # CER (Character Error Rate)
    cer_score = cer(references, hypotheses)
    print(f"ğŸ“ CER (Character Error Rate): {cer_score*100:.2f}%")

    # ìƒ˜í”Œ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“‹ ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ)")
    print("=" * 80)
    for i in range(min(5, len(references))):
        print(f"\n[ìƒ˜í”Œ {i+1}]")
        print(f"ì •ë‹µ: {references[i]}")
        print(f"ì˜ˆì¸¡: {hypotheses[i]}")

    # ê²°ê³¼ ì €ì¥
    results = {
        'per': per_score,
        'cer': cer_score,
        'success_count': success_count,
        'error_count': error_count,
        'total_samples': len(json_files),
    }

    return results


def main():
    parser = argparse.ArgumentParser(description='Test ì…‹ í‰ê°€')
    parser.add_argument('--model', type=str, required=True, help='ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--test_dir', type=str,
                        default='/home/j-k13a206/data/child_subset_100h/3.Test',
                        help='Test ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--gpu', type=str, default='3', help='GPU ë²ˆí˜¸')
    parser.add_argument('--max_samples', type=int, default=None, help='ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')
    parser.add_argument('--output', type=str, default=None, help='ê²°ê³¼ JSON ì €ì¥ ê²½ë¡œ')

    args = parser.parse_args()

    # GPU ì„¤ì •
    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ Device: {device} (GPU {args.gpu})")

    # ëª¨ë¸ ë¡œë“œ
    model, processor = load_model_and_processor(args.model, device)
    g2p = KoreanG2P()

    # í‰ê°€ ì‹¤í–‰
    results = evaluate_test_set(
        model=model,
        processor=processor,
        g2p=g2p,
        test_dir=args.test_dir,
        device=device,
        max_samples=args.max_samples,
    )

    if results is None:
        print("\nâŒ í‰ê°€ ì‹¤íŒ¨!")
        return

    # ê²°ê³¼ ì €ì¥
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    # ìµœì¢… íŒì •
    print("\n" + "=" * 80)
    print("ğŸ† ìµœì¢… íŒì •")
    print("=" * 80)

    per = results['per'] * 100

    if per < 15:
        print(f"âœ… ì„±ê³µ! PER {per:.2f}% < 15% ëª©í‘œ ë‹¬ì„±! ğŸ‰")
    elif per < 18:
        print(f"âš ï¸ ì–‘í˜¸. PER {per:.2f}%ëŠ” ëª©í‘œ(15%)ì— ê·¼ì ‘í–ˆìŠµë‹ˆë‹¤.")
        print("   ì¶”ê°€ í•™ìŠµì´ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì„ ê³ ë ¤í•˜ì„¸ìš”.")
    else:
        print(f"âŒ ëª©í‘œ ë¯¸ë‹¬ì„±. PER {per:.2f}% > 18%")
        print("   ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:")
        print("   1. Learning rate ì¡°ì • (ë” ë‚®ê²Œ)")
        print("   2. ë” ë§ì€ epoch í•™ìŠµ")
        print("   3. ë°ì´í„° í’ˆì§ˆ ì¬í™•ì¸")
        print("   4. Phase 1ë¶€í„° ì¬í•™ìŠµ")

    print("=" * 80)


if __name__ == "__main__":
    main()
