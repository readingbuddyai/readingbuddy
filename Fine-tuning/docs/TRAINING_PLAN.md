# ğŸ¯ ì–´ë¦°ì´ ìŒì„± Wav2Vec2 íŒŒì¸íŠœë‹ ë§ˆìŠ¤í„° í”Œëœ

## ğŸ“‹ ì „ì²´ ê°œìš”

**ëª©í‘œ**: Wav2Vec2-XLS-R-300Mì„ ì–´ë¦°ì´ ìŒì„± 100h ì„œë¸Œì…‹ìœ¼ë¡œ ë‹¨ê³„ë³„ íŒŒì¸íŠœë‹

**ì „ëµ**:
- âœ… í•˜ìœ„ 6-8ì¸µ ë™ê²° + ìƒìœ„ì¸µ LoRA (r=16)
- âœ… 20h â†’ 60h â†’ 100h ë‹¨ê³„ì  í•™ìŠµ (Curriculum Learning)
- âœ… SpecAugment + Speed Perturbation
- âœ… EarlyStopping + EMA
- âœ… í™”ì ë¶„ë¦¬ ì™„ë£Œ (ì„œë¸Œì…‹ ìƒì„± ì‹œ ì ìš©ë¨)

---

## ğŸ—‚ï¸ ë°ì´í„° ì¤€ë¹„ ìƒíƒœ

### âœ… ì™„ë£Œëœ ì‘ì—…
```
/home/j-k13a206/data/child_subset_100h/
â”œâ”€â”€ 1.Training/              # Train ë°ì´í„°
â”œâ”€â”€ 2.Validation_split/      # Validation ë°ì´í„° (í•™ìŠµ ì¤‘ ëª¨ë‹ˆí„°ë§)
â”œâ”€â”€ 3.Test/                  # Test ë°ì´í„° (ìµœì¢… í‰ê°€ìš©, í•™ìŠµ ì‹œ ìˆ¨ê¹€)
â”œâ”€â”€ 2.Validation/            # ì›ë³¸ Validation (ë°±ì—…ìš©)
â”œâ”€â”€ subset_metadata.csv      # ì›ë³¸ ë©”íƒ€ë°ì´í„°
â””â”€â”€ subset_metadata_with_test.csv  # Train/Val/Test ë¶„í•  ë©”íƒ€ë°ì´í„°
```

**íŠ¹ì§•**:
- ì¸µí™” ìƒ˜í”Œë§: ì—°ë ¹/SNR/ê¸¸ì´ ë¶„í¬ ìœ ì§€
- ì–´ë ¤ìš´ ìƒ˜í”Œ 25% í¬í•¨ (ë‚®ì€ SNR, ê¸´ ë°œí™”)
- **í™”ì ì™„ì „ ë¶„ë¦¬**: Train/Val/Test ê°„ í™”ì ì¤‘ë³µ 0ëª…

### ğŸ“Š ìµœì¢… ë°ì´í„° ë¶„í¬ (ì‹¤ì œ)

| Split | ìƒ˜í”Œ ìˆ˜ | ì‹œê°„ | í™”ì ìˆ˜ | ë¹„ìœ¨ |
|-------|---------|------|---------|------|
| **Train** | 57,746ê°œ | **136.19h** | 63ëª… | 91.5% |
| **Val** | 2,715ê°œ | **7.78h** | 9ëª… | 5.2% |
| **Test** | 2,216ê°œ | **4.89h** | 10ëª… | 3.3% |
| **ì „ì²´** | 62,677ê°œ | **148.86h** | 82ëª… | 100% |

**ì£¼ìš” ë³€ê²½ì‚¬í•­**:
- ì›ë˜ ëª©í‘œ 100h â†’ ì‹¤ì œ 148.86h (í™”ì ë‹¨ìœ„ ì„ íƒìœ¼ë¡œ ì¸í•œ ì´ˆê³¼)
- ì´ëŠ” **ì •ìƒì ì´ë©° ì¥ì **:
  - í™”ì ë¶„ë¦¬ ì™„ë²½ ìœ ì§€
  - ë” ë§ì€ í•™ìŠµ ë°ì´í„°
  - ì—¬ì „íˆ 3500hì˜ 4.3%ë¡œ ë¹ ë¥¸ íŒŒì¼ëŸ¿ ê°€ëŠ¥

### ğŸ“Š Phaseë³„ ë°ì´í„° ë¶„í•  ê³„íš (ìˆ˜ì •ë¨)

```python
# 148h ê¸°ì¤€ìœ¼ë¡œ ì¬ê³„ì‚°
Phase 1: 30h   (20% of 148h - ì´ˆê¸° í•™ìŠµìš©)
Phase 2: 90h   (60% of 148h - ë„ë©”ì¸ ì ì‘ìš©)
Phase 3: 148h  (100% - ì „ì²´ ì •ì œìš©)
```

**Phaseë³„ êµ¬í˜„ ë°©ì‹**:
- **Phase 1**: Train ë°ì´í„°ì˜ ì²« 20% ì‚¬ìš© (íŒŒì¼ ìˆœì„œëŒ€ë¡œ)
- **Phase 2**: Train ë°ì´í„°ì˜ ì²« 60% ì‚¬ìš©
- **Phase 3**: Train ë°ì´í„° 100% ì‚¬ìš©
- **Val/Test**: ëª¨ë“  Phaseì—ì„œ ë™ì¼í•˜ê²Œ ìœ ì§€ (7.78h + 4.89h)

---

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

### ë² ì´ìŠ¤ ëª¨ë¸
- **ëª¨ë¸**: `facebook/wav2vec2-xls-r-300m`
- **ì´ ì¸µ ìˆ˜**: 24ì¸µ
- **íŒŒë¼ë¯¸í„°**: ì•½ 300M

### LoRA ì„¤ì •
```python
LoraConfig(
    r=16,                    # Rank
    lora_alpha=32,           # Scaling (r Ã— 2)
    target_modules=[
        "q_proj",            # Query projection
        "k_proj",            # Key projection
        "v_proj",            # Value projection
    ],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM"    # CTC í—¤ë“œìš©
)
```

### ì¸µ ë™ê²° ì „ëµ
```python
# ì˜µì…˜ A: 8ì¸µ ë™ê²° (ì¶”ì²œ)
freeze_layers = list(range(0, 8))    # 0~7ì¸µ ë™ê²°
trainable_layers = 16                # ìƒìœ„ 16ì¸µ í•™ìŠµ

# ì˜µì…˜ B: 12ì¸µ ë™ê²° (ë¹ ë¥¸ ì‹¤í—˜ìš©)
freeze_layers = list(range(0, 12))   # 0~11ì¸µ ë™ê²°
trainable_layers = 12                # ìƒìœ„ 12ì¸µ í•™ìŠµ
```

---

## ğŸ“… Phaseë³„ í•™ìŠµ ê³„íš

### Phase 1: ì´ˆê¸° LoRA í•™ìŠµ (30h)
**ëª©í‘œ**: LoRA ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, ê¸°ë³¸ ë„ë©”ì¸ ì ì‘

| í•­ëª© | ê°’ |
|-----|---|
| ë°ì´í„° | 30h (Trainì˜ 20%) |
| Train ìƒ˜í”Œ | ~11,549ê°œ (57,746ì˜ 20%) |
| Val ìƒ˜í”Œ | 2,715ê°œ (7.78h) |
| Epoch | 10 |
| Learning Rate | 5e-4 |
| Batch Size | 16 |
| Warmup Steps | 500 |
| Weight Decay | 0.01 |
| Gradient Clip | 1.0 |
| **ëª©í‘œ WER** | **< 25%** |

**íŠ¹ì§•**:
- ë†’ì€ LRë¡œ ë¹ ë¥¸ ìˆ˜ë ´
- LoRAë§Œ í•™ìŠµ (Feature Extractor + í•˜ìœ„ì¸µ ë™ê²°)
- SpecAugment ì•½í•˜ê²Œ ì ìš©

**ì˜ˆìƒ ì‹œê°„**: ~4.5ì‹œê°„ (V100 1ëŒ€ ê¸°ì¤€, 30h ê¸°ì¤€)

---

### Phase 2: ë„ë©”ì¸ ì ì‘ (90h)
**ëª©í‘œ**: ì–´ë¦°ì´ ìŒì„± íŠ¹ì„± í•™ìŠµ, ë‹¤ì–‘ì„± í™•ë³´

| í•­ëª© | ê°’ |
|-----|---|
| ë°ì´í„° | 90h (Trainì˜ 60%) |
| Train ìƒ˜í”Œ | ~34,648ê°œ (57,746ì˜ 60%) |
| Val ìƒ˜í”Œ | 2,715ê°œ (7.78h) |
| Epoch | 8 |
| Learning Rate | 3e-4 |
| Batch Size | 16 |
| Warmup Steps | 1000 |
| Weight Decay | 0.01 |
| Gradient Clip | 1.0 |
| **ëª©í‘œ WER** | **< 18%** |

**íŠ¹ì§•**:
- Phase 1 ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì‹œì‘
- ì¤‘ê°„ LRë¡œ ì•ˆì •ì  í•™ìŠµ
- SpecAugment + Speed Perturbation ì ê·¹ í™œìš©

**ì˜ˆìƒ ì‹œê°„**: ~15ì‹œê°„ (V100 1ëŒ€ ê¸°ì¤€, 90h ê¸°ì¤€)

---

### Phase 3: ì „ì²´ ì •ì œ (148h)
**ëª©í‘œ**: ëª¨ë“  ë°ì´í„°ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”

| í•­ëª© | ê°’ |
|-----|---|
| ë°ì´í„° | 148h (Train ì „ì²´ 100%) |
| Train ìƒ˜í”Œ | 57,746ê°œ |
| Val ìƒ˜í”Œ | 2,715ê°œ (7.78h) |
| Epoch | 5 |
| Learning Rate | 1e-4 |
| Batch Size | 16 |
| Warmup Steps | 500 |
| Weight Decay | 0.01 |
| Gradient Clip | 1.0 |
| **ëª©í‘œ WER** | **< 15%** |

**íŠ¹ì§•**:
- Phase 2 ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì‹œì‘
- ë‚®ì€ LRë¡œ ì„¸ë°€ ì¡°ì •
- EarlyStopping patience=3

**ì˜ˆìƒ ì‹œê°„**: ~18ì‹œê°„ (V100 1ëŒ€ ê¸°ì¤€, 148h ê¸°ì¤€)

---

### Phase 4: ì†Œí”„íŠ¸ ì „í•´ë™ (ì„ íƒì‚¬í•­)
**ëª©í‘œ**: ê·¹ì € LRë¡œ ì „ì²´ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •

| í•­ëª© | ê°’ |
|-----|---|
| ë°ì´í„° | 148h (Train ì „ì²´ 100%) |
| Train ìƒ˜í”Œ | 57,746ê°œ |
| Val ìƒ˜í”Œ | 2,715ê°œ (7.78h) |
| Epoch | 2 |
| Learning Rate | 5e-5 |
| Batch Size | 16 |
| Weight Decay | 0.01 |
| **ëª©í‘œ WER ê°œì„ ** | **0.5~1.0%** |

**ì£¼ì˜**:
- Phase 3 Val WERì´ ë” ë–¨ì–´ì§€ì§€ ì•Šìœ¼ë©´ **SKIP**
- ëª¨ë“  ì¸µ í•´ë™ (ê³¼ì í•© ìœ„í—˜)
- EarlyStopping patience=1

**ì˜ˆìƒ ì‹œê°„**: ~7ì‹œê°„ (V100 1ëŒ€ ê¸°ì¤€, 148h ê¸°ì¤€)

---

## ğŸ¨ Data Augmentation

### SpecAugment
```python
SpecAugment(
    time_mask_width_range=(0, 30),   # ì–´ë¦°ì´ ìŒì„±ì€ ì§§ê²Œ
    freq_mask_width_range=(0, 15),
    num_time_mask=2,
    num_freq_mask=2,
)
```

### Speed Perturbation
```python
SpeedPerturb(
    factors=[0.9, 1.0, 1.1],  # ì–´ë¦°ì´ëŠ” ì†ë„ ë³€í™” í¼
    p=0.5                     # 50% í™•ë¥ ë¡œ ì ìš©
)
```

### Phaseë³„ ê°•ë„
| Phase | SpecAugment | Speed Perturb | ì´ìœ  |
|-------|-------------|---------------|-----|
| 1 (20h) | ì•½í•¨ (50%) | ì—†ìŒ | ì•ˆì •ì  ì´ˆê¸° í•™ìŠµ |
| 2 (60h) | ê°•í•¨ (100%) | ìˆìŒ (50%) | Robustness í–¥ìƒ |
| 3 (100h) | ì¤‘ê°„ (75%) | ìˆìŒ (50%) | ê³¼ì í•© ë°©ì§€ |
| 4 (ì„ íƒ) | ì—†ìŒ | ì—†ìŒ | ìˆœìˆ˜ ì„±ëŠ¥ ê·¹ëŒ€í™” |

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­

### í•„ìˆ˜ ë©”íŠ¸ë¦­
```python
metrics = {
    'train/loss',              # í•™ìŠµ ì†ì‹¤
    'train/lr',                # Learning Rate
    'val/loss',                # ê²€ì¦ ì†ì‹¤
    'val/wer',                 # â­ í•µì‹¬: Word Error Rate
    'val/cer',                 # Character Error Rate
    'grad_norm',               # Gradient í­ë°œ ê°ì§€
    'epoch_time',              # ì—í­ë‹¹ ì†Œìš” ì‹œê°„
}
```

### ì¶”ê°€ ë©”íŠ¸ë¦­ (ê¶Œì¥)
```python
advanced_metrics = {
    'val/wer_by_age',          # ì—°ë ¹ë³„ WER
    'val/wer_by_snr',          # SNRë³„ WER
    'val/phoneme_error_rate',  # ìŒì†Œ ë‹¨ìœ„ ì—ëŸ¬
    'model/trainable_params',  # í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„° ìˆ˜
}
```

---

## ğŸ”§ EarlyStopping ì „ëµ

### Phaseë³„ ì„¤ì •
```python
# Phase 1 (20h, 10 epoch)
EarlyStopping(
    monitor='val_wer',
    patience=4,              # 4 epoch ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
    min_delta=0.01,          # 1% ì´ìƒ ê°œì„ 
    mode='min'
)

# Phase 2 (60h, 8 epoch)
EarlyStopping(
    monitor='val_wer',
    patience=3,
    min_delta=0.005,         # 0.5% ì´ìƒ ê°œì„ 
    mode='min'
)

# Phase 3 (100h, 5 epoch)
EarlyStopping(
    monitor='val_wer',
    patience=3,
    min_delta=0.005,
    mode='min'
)

# Phase 4 (ì„ íƒ, 2 epoch)
EarlyStopping(
    monitor='val_wer',
    patience=1,              # 1 epochë§Œ ê¸°ë‹¤ë¦¼
    min_delta=0.002,         # 0.2% ì´ìƒ ê°œì„ 
    mode='min'
)
```

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### Phaseë³„ ëª©í‘œ WER
| Phase | ë°ì´í„° | ëª©í‘œ WER | ìµœì†Œ í—ˆìš© | íŒë‹¨ ê¸°ì¤€ |
|-------|--------|---------|---------|---------|
| Phase 1 (30h) | 30h | < 25% | < 30% | ê¸°ë³¸ í•™ìŠµ ì„±ê³µ |
| Phase 2 (90h) | 90h | < 18% | < 22% | ë„ë©”ì¸ ì ì‘ ì„±ê³µ |
| Phase 3 (148h) | 148h | < 15% | < 18% | íŒŒì¼ëŸ¿ ì„±ê³µ â­ |
| Phase 4 (ì„ íƒ) | 148h | < 14% | < 15% | ì¶”ê°€ ê°œì„  |

### Phase 3 ì„±ê³µ ì‹œ (WER < 15%)
â†’ **3500h ì „ì²´ ë°ì´í„°ë¡œ í™•ì¥ ê°€ëŠ¥!**

### Phase 3 ì‹¤íŒ¨ ì‹œ (WER > 18%)
â†’ **ë°ì´í„° í’ˆì§ˆ ì ê²€ í•„ìš”**
- ì „ì‚¬ ì •í™•ë„ ì¬í™•ì¸
- ë…¸ì´ì¦ˆ ë ˆë²¨ ì ê²€
- ì„œë¸Œì…‹ ì¬ìƒ˜í”Œë§ ê³ ë ¤

---

## â±ï¸ ì´ ì˜ˆìƒ ì‹œê°„ (ìˆ˜ì •ë¨)

| Phase | ì‹œê°„ (V100 1ëŒ€) | ëˆ„ì  |
|-------|----------------|------|
| Phase 1 (30h) | ~4.5ì‹œê°„ | 4.5h |
| Phase 2 (90h) | ~15ì‹œê°„ | 19.5h |
| Phase 3 (148h) | ~18ì‹œê°„ | 37.5h |
| Phase 4 (ì„ íƒ) | ~7ì‹œê°„ | 44.5h |
| **ì´í•© (Phase 1~3)** | **~37.5ì‹œê°„** | - |

**ì°¸ê³ **: ì›ë˜ ê³„íš ëŒ€ë¹„ ì•½ 50% ì‹œê°„ ì¦ê°€ (100h â†’ 148h)
í•˜ì§€ë§Œ ì—¬ì „íˆ 3500h í•™ìŠµ(400~600h) ëŒ€ë¹„ **1/10 ìˆ˜ì¤€**

---

## ğŸ—ƒï¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬

### ì €ì¥ ì „ëµ
```
fine_tunining_new/checkpoints/
â”œâ”€â”€ phase1_20h/
â”‚   â”œâ”€â”€ best_model/                    # Best WER ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ preprocessor_config.json
â”‚   â”œâ”€â”€ final_model/                   # ë§ˆì§€ë§‰ epoch
â”‚   â””â”€â”€ training_log.json
â”œâ”€â”€ phase2_60h/
â”‚   â”œâ”€â”€ best_model/
â”‚   â”œâ”€â”€ final_model/
â”‚   â””â”€â”€ training_log.json
â”œâ”€â”€ phase3_100h/
â”‚   â”œâ”€â”€ best_model/
â”‚   â”œâ”€â”€ final_model/
â”‚   â””â”€â”€ training_log.json
â””â”€â”€ phase4_full_finetune/ (ì„ íƒ)
    â”œâ”€â”€ best_model/
    â”œâ”€â”€ final_model/
    â””â”€â”€ training_log.json
```

### ì €ì¥ ì¡°ê±´
- **Best Model**: Val WER ìµœì € ê°±ì‹  ì‹œ
- **Final Model**: ê° Phase ë§ˆì§€ë§‰ epoch
- **ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸**: ë§¤ epoch (ë””ìŠ¤í¬ ì—¬ìœ  ìˆìœ¼ë©´)

---

## ğŸ“ˆ 100h â†’ 3500h í™•ì¥ ì „ëµ

### ì˜µì…˜ A: Direct Scale-Up (ì¶”ì²œ)
```
Phase 3 (100h, WER 15%)
  â†“
3500h ì „ì²´ í•™ìŠµ
  - Epoch: 3~5
  - LR: 1e-4 â†’ 5e-5 (ê°ì†Œ)
  - ë™ì¼í•œ augmentation
  â†“
ì˜ˆìƒ WER: 12~14%
```

### ì˜µì…˜ B: Curriculum Learning
```
100h (WER 15%)
  â†“
500h (WER 14%)
  â†“
1500h (WER 13%)
  â†“
3500h (WER 12%)
```

### ì˜µì…˜ C: Active Learning
```
100h ëª¨ë¸ë¡œ 3500h ì˜ˆì¸¡
  â†“
ë†’ì€ WER ìƒ˜í”Œ ìš°ì„  í•™ìŠµ
  â†“
ì ì§„ì  í™•ì¥
```

---

## ğŸš€ ì‹¤í–‰ ìˆœì„œ

### Step 1: ë°ì´í„° ë¶„í• 
```bash
python prepare_phase_data.py \
  --input_dir /home/j-k13a206/data/child_subset_100h \
  --output_dir /home/j-k13a206/fine_tunining_new/data \
  --phase1_ratio 0.2 \
  --phase2_ratio 0.6 \
  --phase3_ratio 1.0
```

### Step 2: Phase 1 ì‹¤í–‰
```bash
python train_phase1.py \
  --data_dir ./data/phase1_20h \
  --output_dir ./checkpoints/phase1_20h \
  --epochs 10 \
  --lr 5e-4 \
  --batch_size 16
```

### Step 3: Phase 2 ì‹¤í–‰
```bash
python train_phase2.py \
  --data_dir ./data/phase2_60h \
  --resume_from ./checkpoints/phase1_20h/best_model \
  --output_dir ./checkpoints/phase2_60h \
  --epochs 8 \
  --lr 3e-4
```

### Step 4: Phase 3 ì‹¤í–‰
```bash
python train_phase3.py \
  --data_dir ./data/phase3_100h \
  --resume_from ./checkpoints/phase2_60h/best_model \
  --output_dir ./checkpoints/phase3_100h \
  --epochs 5 \
  --lr 1e-4
```

### Step 5: Phase 4 ì‹¤í–‰ (ì„ íƒ)
```bash
# Phase 3 ê²°ê³¼ í™•ì¸ í›„ ê²°ì •
python train_phase4.py \
  --data_dir ./data/phase3_100h \
  --resume_from ./checkpoints/phase3_100h/best_model \
  --output_dir ./checkpoints/phase4_full_finetune \
  --epochs 2 \
  --lr 5e-5 \
  --unfreeze_all
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í–‰ ì „
- [ ] `/home/j-k13a206/data/child_subset_100h` ì¡´ì¬ í™•ì¸
- [ ] `subset_metadata.csv`ì— í™”ì ID í¬í•¨ í™•ì¸
- [ ] GPU ë©”ëª¨ë¦¬ í™•ì¸ (ìµœì†Œ 16GB)
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (ìµœì†Œ 100GB)
- [ ] í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ (`transformers`, `peft`, `torchaudio`)

### Phase 1 í›„
- [ ] Val WER < 30%
- [ ] Lossê°€ ìˆ˜ë ´í•¨
- [ ] Gradient í­ë°œ ì—†ìŒ
- [ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ

### Phase 2 í›„
- [ ] Val WER < 22%
- [ ] Phase 1ë³´ë‹¤ ê°œì„ ë¨
- [ ] ê³¼ì í•© ì§•í›„ ì—†ìŒ

### Phase 3 í›„
- [ ] Val WER < 18% (â­ í•µì‹¬)
- [ ] Phase 2ë³´ë‹¤ ê°œì„ ë¨
- [ ] ìµœì¢… ëª¨ë¸ safetensors ì €ì¥

### 3500h í™•ì¥ ì „
- [ ] Phase 3 WER < 15%
- [ ] ì—°ë ¹ë³„/SNRë³„ ì„±ëŠ¥ ê· í˜•ì 
- [ ] ë°ì´í„° í’ˆì§ˆ ì¬í™•ì¸

---

## ğŸ“ ì°¸ê³  ìë£Œ

- **LoRA ë…¼ë¬¸**: [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685)
- **Wav2Vec2**: [Hugging Face Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)
- **Curriculum Learning**: [Bengio et al. 2009](https://qmro.qmul.ac.uk/xmlui/handle/123456789/15972)

---

## ğŸ’¬ FAQ

**Q: Phase 1ì´ ë„ˆë¬´ ëŠë ¤ìš”**
A: Batch sizeë¥¼ 8ë¡œ ì¤„ì´ê±°ë‚˜, 12ì¸µ ë™ê²°ë¡œ ë³€ê²½

**Q: Phase 3ì—ì„œ WER 20% ì´ìƒì´ì—ìš”**
A: ë°ì´í„° í’ˆì§ˆ ì¬ì ê²€, ì„œë¸Œì…‹ ì¬ìƒ˜í”Œë§ ê³ ë ¤

**Q: Phase 4ë¥¼ ê¼­ í•´ì•¼ í•˜ë‚˜ìš”?**
A: ì•„ë‹ˆìš”. Phase 3ì—ì„œ ëª©í‘œ ë‹¬ì„±í•˜ë©´ skip

**Q: 3500hëŠ” ì–¸ì œ í•™ìŠµí•˜ë‚˜ìš”?**
A: Phase 3 WER < 15% ë‹¬ì„± í›„, ë™ì¼ ì„¤ì •ìœ¼ë¡œ ë°”ë¡œ í™•ì¥

---

**ì‘ì„±ì¼**: 2025-11-06
**ë²„ì „**: v1.0
**ìƒíƒœ**: ì¤€ë¹„ ì™„ë£Œ âœ…
