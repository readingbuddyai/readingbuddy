# ğŸš€ train_all_phases.py ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì „ì²´ Phase (1â†’2â†’3)ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì‹¤í–‰í•˜ëŠ” í†µí•© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

**íŠ¹ì§•**:
- âœ… LoRA (r=16) + í•˜ìœ„ 8ì¸µ ë™ê²°
- âœ… Phase ê°„ ìë™ ì²´í¬í¬ì¸íŠ¸ ì—°ê²°
- âœ… í™”ì ë¶„ë¦¬ ë°ì´í„° (Train/Val/Test)
- âœ… 30h â†’ 90h â†’ 148h Curriculum Learning
- âœ… EarlyStopping + ìƒì„¸ ë¡œê¹…

---

## ğŸ¯ ì‹¤í–‰ ë°©ë²•

### ì˜µì…˜ 1: Phase 1ë§Œ ì‹¤í–‰ (ì¶”ì²œ - ë¨¼ì € í…ŒìŠ¤íŠ¸)

```bash
cd /home/j-k13a206/fine_tunining_new

python3 train_all_phases.py --phase 1 --gpu 1
```

**ì˜ˆìƒ ì‹œê°„**: ~4.5ì‹œê°„
**ëª©í‘œ WER**: < 25%

---

### ì˜µì…˜ 2: Phase 2 ì‹¤í–‰ (Phase 1 ì™„ë£Œ í›„)

```bash
python3 train_all_phases.py \
  --phase 2 \
  --resume_from ./checkpoints/phase1_30h/checkpoint-best \
  --gpu 1
```

**ì˜ˆìƒ ì‹œê°„**: ~15ì‹œê°„
**ëª©í‘œ WER**: < 18%

---

### ì˜µì…˜ 3: Phase 3 ì‹¤í–‰ (Phase 2 ì™„ë£Œ í›„)

```bash
python3 train_all_phases.py \
  --phase 3 \
  --resume_from ./checkpoints/phase2_90h/checkpoint-best \
  --gpu 1
```

**ì˜ˆìƒ ì‹œê°„**: ~18ì‹œê°„
**ëª©í‘œ WER**: < 15% â­

---

### ì˜µì…˜ 4: ì „ì²´ ìë™ ì‹¤í–‰ (1â†’2â†’3)

```bash
# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ì¶”ì²œ)
nohup python3 train_all_phases.py --phase all --gpu 1 > training_all.log 2>&1 &

# ë¡œê·¸ í™•ì¸
tail -f training_all.log
```

**ì˜ˆìƒ ì´ ì‹œê°„**: ~37.5ì‹œê°„
**ì£¼ì˜**: ì¤‘ê°„ì— ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ Phaseë§Œ ì¬ì‹¤í–‰ ê°€ëŠ¥

---

## ğŸ“‚ ì¶œë ¥ êµ¬ì¡°

```
fine_tunining_new/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ phase1_30h/
â”‚   â”‚   â”œâ”€â”€ checkpoint-best/          # Best ëª¨ë¸ (Val loss ìµœì €)
â”‚   â”‚   â”œâ”€â”€ final_model/              # ë§ˆì§€ë§‰ epoch ëª¨ë¸
â”‚   â”‚   â””â”€â”€ phase1_30h_training.log   # í•™ìŠµ ë¡œê·¸
â”‚   â”œâ”€â”€ phase2_90h/
â”‚   â”‚   â”œâ”€â”€ checkpoint-best/
â”‚   â”‚   â”œâ”€â”€ final_model/
â”‚   â”‚   â””â”€â”€ phase2_90h_training.log
â”‚   â””â”€â”€ phase3_148h/
â”‚       â”œâ”€â”€ checkpoint-best/
â”‚       â”œâ”€â”€ final_model/
â”‚       â””â”€â”€ phase3_148h_training.log
â””â”€â”€ train_all_phases.py
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

```bash
# Phase 1 ë¡œê·¸
tail -f checkpoints/phase1_30h/phase1_30h_training.log

# ì „ì²´ ì‹¤í–‰ ë¡œê·¸ (--phase all ì‚¬ìš© ì‹œ)
tail -f training_all.log
```

### GPU ì‚¬ìš©ë¥  í™•ì¸

```bash
watch -n 1 nvidia-smi
```

### í•™ìŠµ ì§„í–‰ ìƒí™©

```bash
# Trainer ë¡œê·¸ (ìë™ ìƒì„±)
ls -lh checkpoints/phase1_30h/checkpoint-*/
```

---

## ğŸ›ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### GPU ë³€ê²½

```bash
python3 train_all_phases.py --phase 1 --gpu 0  # GPU 0 ì‚¬ìš©
python3 train_all_phases.py --phase 1 --gpu 2  # GPU 2 ì‚¬ìš©
```

### Batch Size ë³€ê²½

`train_all_phases.py` íŒŒì¼ ìˆ˜ì •:

```python
COMMON_CONFIG = {
    'batch_size': 8,  # 16 â†’ 8 (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
    ...
}
```

### Learning Rate ë³€ê²½

```python
PHASE_CONFIG = {
    1: {
        'learning_rate': 3e-4,  # 5e-4 â†’ 3e-4 (ë” ì•ˆì •ì )
        ...
    }
}
```

### Epoch ìˆ˜ ì¡°ì •

```python
PHASE_CONFIG = {
    1: {
        'epochs': 5,  # 10 â†’ 5 (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
        ...
    }
}
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. CUDA Out of Memory

**í•´ê²°ì±…**:
```python
# Batch size ì¤„ì´ê¸°
'batch_size': 8,  # ë˜ëŠ” 4

# Gradient accumulation ì‚¬ìš©
'gradient_accumulation_steps': 2,
```

### 2. Phase 2/3 ì‹¤í–‰ ì‹œ ì²´í¬í¬ì¸íŠ¸ ì—ëŸ¬

**ì¦ìƒ**: `--resume_from` ê²½ë¡œê°€ ì—†ë‹¤ëŠ” ì˜¤ë¥˜

**í•´ê²°ì±…**:
```bash
# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™•ì¸
ls -la checkpoints/phase1_30h/checkpoint-best/

# ì˜¬ë°”ë¥¸ ê²½ë¡œ ì§€ì •
python3 train_all_phases.py \
  --phase 2 \
  --resume_from checkpoints/phase1_30h/checkpoint-best
```

### 3. í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼

**ì›ì¸**: DataLoader workers ë¶€ì¡±

**í•´ê²°ì±…**:
```python
COMMON_CONFIG = {
    'num_workers': 64,  # 48 â†’ 64 (CPU ì—¬ìœ  ìˆìœ¼ë©´)
    'prefetch_factor': 16,  # 10 â†’ 16
}
```

### 4. Eval Lossê°€ ì¤„ì§€ ì•ŠìŒ

**ì¦ìƒ**: Val lossê°€ ê³„ì† ë†’ê±°ë‚˜ ì¦ê°€

**í•´ê²°ì±…**:
- Learning rate ì¤„ì´ê¸° (5e-4 â†’ 3e-4)
- ë°ì´í„° í’ˆì§ˆ ì¬í™•ì¸
- Phase 1ì´ ì˜ ìˆ˜ë ´í–ˆëŠ”ì§€ í™•ì¸ (< 25% WER)

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í–‰ ì „
- [ ] `/home/j-k13a206/data/child_subset_100h` ì¡´ì¬
- [ ] `1.Training/` ë””ë ‰í† ë¦¬ í™•ì¸
- [ ] `2.Validation_split/` ë””ë ‰í† ë¦¬ í™•ì¸ (Valìš©)
- [ ] GPU ë©”ëª¨ë¦¬ 16GB ì´ìƒ
- [ ] ë””ìŠ¤í¬ ê³µê°„ 100GB ì´ìƒ
- [ ] `peft` íŒ¨í‚¤ì§€ ì„¤ì¹˜: `pip install peft`

### Phase 1 ì™„ë£Œ í›„
- [ ] Val loss < 0.5
- [ ] WER < 25%
- [ ] `checkpoint-best/` ì¡´ì¬

### Phase 2 ì™„ë£Œ í›„
- [ ] Val loss < 0.3
- [ ] WER < 18%
- [ ] Phase 1ë³´ë‹¤ ê°œì„ ë¨

### Phase 3 ì™„ë£Œ í›„
- [ ] Val loss < 0.2
- [ ] WER < 15% â­
- [ ] ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

### Phase 3 ì„±ê³µ ì‹œ (WER < 15%)

```bash
# 1. Test ì…‹ìœ¼ë¡œ ìµœì¢… í‰ê°€
python3 evaluate_test.py \
  --model checkpoints/phase3_148h/checkpoint-best \
  --test_dir /home/j-k13a206/data/child_subset_100h/3.Test

# 2. 3500h ì „ì²´ ë°ì´í„°ë¡œ í™•ì¥
# (ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ í•„ìš”)
```

### Phase 3 ì‹¤íŒ¨ ì‹œ (WER > 18%)

1. ë°ì´í„° í’ˆì§ˆ ì¬í™•ì¸
2. Learning rate ì¡°ì •
3. Phase 1ë¶€í„° ì¬ì‹¤í–‰
4. ì„œë¸Œì…‹ ì¬ìƒ˜í”Œë§ ê³ ë ¤

---

## ğŸ“ ì°¸ê³ 

**í•™ìŠµ ì„¤ì • ìš”ì•½**:

| Phase | ë°ì´í„° | Epochs | LR | ì‹œê°„ | ëª©í‘œ WER |
|-------|--------|--------|-----|------|---------|
| 1 | 30h | 10 | 5e-4 | 4.5h | <25% |
| 2 | 90h | 8 | 3e-4 | 15h | <18% |
| 3 | 148h | 5 | 1e-4 | 18h | <15% |

**LoRA ì„¤ì •**:
- r=16, alpha=32
- target: q_proj, k_proj, v_proj
- í•˜ìœ„ 8ì¸µ ë™ê²° (0~7)

**ë°ì´í„° ë¶„í¬**:
- Train: 136.19h (63ëª… í™”ì)
- Val: 7.78h (9ëª… í™”ì)
- Test: 4.89h (10ëª… í™”ì)
- í™”ì ì¤‘ë³µ: 0ëª… âœ…

---

**Good luck! ğŸš€**
