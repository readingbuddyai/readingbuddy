from fastapi import FastAPI, UploadFile, Form, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import Dict, List
from pathlib import Path
import json
import os
import torch
import numpy as np
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
from .utils_audio import load_audio_to_mono_16k

# os.environ["TRANSFORMERS_OFFLINE"] = "1"

BASE_DIR = Path(__file__).resolve().parent  # .../src
PROJECT_ROOT = BASE_DIR.parent              # í”„ë¡œì íŠ¸ ë£¨íŠ¸
MODEL_PATH = PROJECT_ROOT / "models" / "slplab_wav2vec2_korean"
TARGETS_PATH = BASE_DIR / "targets.json"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

app = FastAPI(title="Korean Phoneme Checker", version="0.2.1")

# CORS (ì›í•˜ë©´ ë„ë©”ì¸/ì•„ì´í”¼ ë„£ìœ¼ì„¸ìš”)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],      # í•„ìš”ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------- ëª¨ë¸ ë¡œë“œ ----------
try:
    processor = Wav2Vec2Processor.from_pretrained(str(MODEL_PATH))
    model = Wav2Vec2ForCTC.from_pretrained(str(MODEL_PATH)).to(DEVICE)
    model.eval()
except Exception as e:
    raise RuntimeError(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ---------- TARGETS ë¡œë“œ ----------
if not TARGETS_PATH.exists():
    raise FileNotFoundError(f"targets.jsonì´ ì—†ìŠµë‹ˆë‹¤: {TARGETS_PATH}")
with open(TARGETS_PATH, "r", encoding="utf-8") as f:
    TARGETS: Dict[str, List[str]] = json.load(f)

SPECIAL_TOKENS = {"<s>", "</s>", "|", "[PAD]", "[UNK]"}  # (3) ë””ì½”ë”© ì •ì œìš©

# ==========================
# ğŸ”¹ Utility functions
# ==========================

def get_vocab_maps():
    vocab_to_id = processor.tokenizer.get_vocab()
    id_to_vocab = {v: k for k, v in vocab_to_id.items()}
    return vocab_to_id, id_to_vocab

@torch.no_grad()
def infer_logits(wave_16k: np.ndarray) -> torch.Tensor:
    inputs = processor(wave_16k, sampling_rate=16000, return_tensors="pt", padding="longest")
    input_values = inputs.input_values.to(DEVICE)
    attn = inputs.attention_mask.to(DEVICE) if "attention_mask" in inputs else None
    logits = model(input_values, attention_mask=attn).logits  # [B, T, V]
    return logits.squeeze(0)

def ctc_decode(logits: torch.Tensor) -> str:
    ids = torch.argmax(logits, dim=-1).detach().cpu().numpy()
    return processor.batch_decode(torch.tensor([ids]))[0]

def clean_tokens(seq: str) -> List[str]:
    """íŠ¹ìˆ˜í† í° ì œê±° + ê³µë°± ë¶„ë¦¬"""
    toks = [t for t in seq.split() if t and t not in SPECIAL_TOKENS]
    return toks

def transcribe_audio(file: UploadFile) -> Dict:
    """íŒŒì¼ì„ ë°›ì•„ì„œ ë””ì½”ë”© ê²°ê³¼ë¥¼ ë°˜í™˜ (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)"""
    try:
        # UploadFileì€ ë‚´ë¶€ì ìœ¼ë¡œ SpooledTemporaryFileì´ë¯€ë¡œ .file ê·¸ëŒ€ë¡œ ì „ë‹¬ ê°€ëŠ¥
        wave = load_audio_to_mono_16k(file.file)  # 16k mono numpy
    except Exception as e:
        raise HTTPException(status_code=422, detail=f"ì˜¤ë””ì˜¤ ë¡œë”© ì‹¤íŒ¨: {e}")
    logits = infer_logits(wave)
    decoded = ctc_decode(logits)
    return {"decoded_sequence": decoded}

# ==========================
# ğŸ”¹ API routes
# ==========================

@app.get("/health")
def health():
    return {"status": "ok", "device": DEVICE}

@app.get("/vocab")
def vocab():
    vocab_to_id, _ = get_vocab_maps()
    return {"size": len(vocab_to_id), "vocab": vocab_to_id}

@app.get("/targets")
def targets(key: str = None):
    """(ë³´ë„ˆìŠ¤) TARGETS ì¡°íšŒìš© â€“ key ì—†ìœ¼ë©´ ì „ì²´ sizeë§Œ"""
    if key:
        if key not in TARGETS:
            raise HTTPException(status_code=404, detail=f"unknown target_key: {key}")
        return {key: TARGETS[key]}
    return {"size": len(TARGETS)}

@app.post("/check_phoneme")
async def check_phoneme(file: UploadFile, target_key: str = Form(...)):
    """
    ì‚¬ìš©ìê°€ ë°œìŒí•œ ìŒì„±ì´ target_key(ì˜ˆ: 'ã„±+ã…')ì™€ 'ì •í™•íˆ' ì¼ì¹˜í•˜ëŠ”ì§€ íŒë³„
    - ê¸¸ì´ / ìˆœì„œ ëª¨ë‘ ë™ì¼í•´ì•¼ ì •ë‹µ
    """
    if target_key not in TARGETS:
        return JSONResponse(status_code=400, content={"error": f"unknown target_key: {target_key}"})

    # 1) ì¶”ë¡ 
    result = transcribe_audio(file)

    # 2) ëª©í‘œ ì‹¬ë³¼
    target_symbols: List[str] = TARGETS.get(target_key, [])
    if not isinstance(target_symbols, list) or not all(isinstance(s, str) for s in target_symbols):
        raise HTTPException(status_code=500, detail=f"TARGETS í˜•ì‹ ì˜¤ë¥˜: {target_key} -> {target_symbols}")

    # 3) ë””ì½”ë”© í† í° ì •ì œ + ì—„ê²© ë§¤ì¹­ (4)
    decoded_tokens = clean_tokens(result["decoded_sequence"])  # íŠ¹ìˆ˜í† í° ì œê±°
    is_correct = (decoded_tokens == target_symbols)

    feedback = (
        f"ì •ë‹µì´ì—ìš”! '{target_key}'ë¥¼ ì •í™•íˆ ë°œìŒí–ˆì–´ìš”."
        if is_correct else
        f"'{target_key}' ë°œìŒì´ ì•„ë‹ˆì—ìš”. ë‹¤ì‹œ ì‹œë„í•´ë³¼ê¹Œìš”?"
    )

    return {
        "target_key": target_key,
        "target_symbols": target_symbols,
        "decoded_sequence": result["decoded_sequence"],
        "decoded_tokens": decoded_tokens,         # (ë””ë²„ê¹…/í™•ì¸ìš©)
        "is_correct": is_correct,
        "feedback": feedback
    }
